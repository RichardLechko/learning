# 7.3 Variable Storage

Variable storage determines how variables are allocated, accessed, and managed in memory. Understanding the three fundamental storage types is crucial for writing efficient code and understanding performance characteristics.

## Storage Type Overview

Variables require storage in memory and retrieval mechanisms. The compiler binds memory addresses to variables, and if multiple memory locations are needed, the system binds the first location and calculates subsequent locations at runtime.

**Three types of memory address binding:**
1. **Static Binding** - Address determined before execution
2. **Automatic Binding** - Address determined at function call
3. **Dynamic Binding** - Address determined by explicit allocation

The storage type determines whether a variable is static, automatic, or dynamic based on how memory addresses are bound.

## 7.3.1 Static Binding and Static Variables

Static variables have their memory addresses bound before program execution begins. This early binding provides performance benefits but at the cost of memory consumption throughout the program's lifetime.

### 7.3.1.1 When Static Binding Occurs

Static binding can happen at four different times:

**1. Language Design Time**
- Reserved memory addresses for special purposes
- I/O device memory locations
- Hardware-specific addresses

**2. Compile Time**
- When compiler knows the final memory layout
- Embedded systems with fixed memory maps
- Position-dependent code

**3. Link Time**
- Most common for traditional static linking
- Linker combines object files and assigns final addresses
- External variable resolution

**4. Load Time (Most Common)**
- Modern approach using relocation information
- OS decides final addresses when loading program
- Enables ASLR and virtual memory benefits

### 7.3.1.2 Static Variable Implementation

**Source Code Example:**
```c
static int counter = 5;
static int total = 6;

int main(int argc, char **argv) {
    counter = total + 3;
    total = counter + 2;
    printf("%d %d\n", counter, total);
    return 0;
}
```

**Assembly Implementation:**
```assembly
# Static variables stored in data segment
.data
    .align 4
    .type counter, @object
    .size counter, 4
counter:
    .long 5                    # Initial value stored in executable

    .align 4  
    .type total, @object
    .size total, 4
total:
    .long 6                    # Initial value stored in executable

# Access pattern: counter = total + 3
movl total(%rip), %eax         # Load total using RIP-relative addressing
addl $3, %eax                  # Add 3
movl %eax, counter(%rip)       # Store to counter using RIP-relative addressing

# Access pattern: total = counter + 2  
movl counter(%rip), %eax       # Load counter
addl $2, %eax                  # Add 2
movl %eax, total(%rip)         # Store to total
```

### 7.3.1.3 Modern Static Variable Addressing

**RIP-Relative Addressing (Position Independent Code):**
```assembly
# Modern approach - secure and relocatable
movl variable(%rip), %eax      # Address = RIP + displacement

# Old approach - vulnerable and fixed
movl $0x404000, %eax          # Hardcoded absolute address
```

**Benefits of RIP-Relative:**
- Enables ASLR for security
- Smaller instruction encoding
- Position independence for shared libraries
- Better cache utilization

### 7.3.1.4 Static Variable Advantages

**1. Efficient Access**
```assembly
# Direct addressing - single instruction
movl variable(%rip), %eax      # One memory access
```

**2. No Setup Overhead**
```c
void function() {
    static int call_count = 0;  // No initialization code in function
    call_count++;               // Direct increment
}
```

**3. Value Persistence**
```c
int get_next_id() {
    static int last_id = 1000;
    return ++last_id;           // Retains value between calls
}
```

**4. Thread Sharing**
```c
static int shared_counter = 0;

void thread_function() {
    shared_counter++;           // All threads see same variable
}
```

### 7.3.1.5 Static Variable Disadvantages

**1. Permanent Memory Consumption**
```c
static int huge_array[1000000]; // Consumes 4MB for entire program lifetime
                                // Even if only used once
```

**2. Large Instruction Encoding**
```assembly
# RIP-relative still requires 32-bit displacement
movl variable(%rip), %eax      # 7 bytes: opcode + ModR/M + displacement
```

**3. Thread Safety Issues**
```c
static int counter = 0;

void unsafe_increment() {
    counter++;                  // RACE CONDITION in multi-threaded code
}

void safe_increment() {
    pthread_mutex_lock(&mutex);
    counter++;                  // Protected access
    pthread_mutex_unlock(&mutex);
}
```

**4. Non-Reentrant Code**
```c
char* format_number(int n) {
    static char buffer[32];     // PROBLEM: shared between all calls
    sprintf(buffer, "%d", n);
    return buffer;              // Subsequent calls overwrite buffer
}
```

## 7.3.2 Automatic Binding and Automatic Variables

Automatic variables have their storage allocated at runtime when a function is called and deallocated when the function returns. Despite runtime allocation, the memory layout is determined at compile time.

### 7.3.2.1 Why "Pseudo-Static"?

Automatic variables are called "pseudo-static" because:
- **Storage location**: Determined at runtime (dynamic)
- **Offset calculation**: Determined at compile time (static)

```c
void function(int a, int b) {
    int x, y, z;
    // Compiler knows: x at -4(%rbp), y at -8(%rbp), z at -12(%rbp)
    // But %rbp value determined when function called
}
```

### 7.3.2.2 Activation Records (Stack Frames)

**Modern x86-64 Activation Record Layout:**
```
Higher Memory Addresses
┌─────────────────────┐
│ Argument 7          │ +24(%rbp)  [if more than 6 args]
│ Argument 6          │ +16(%rbp)  [if more than 6 args]  
│ Return Address      │ +8(%rbp)   [pushed by CALL]
│ Saved RBP           │ ← %rbp     [function prologue]
│ Local Variable 1    │ -8(%rbp)
│ Local Variable 2    │ -16(%rbp)
│ Local Variable 3    │ -24(%rbp)
│ Temporary Storage   │ -32(%rbp)
│ ...                 │ ← %rsp
└─────────────────────┘
Lower Memory Addresses
```

### 7.3.2.3 Modern Calling Convention (System V ABI)

**Register Parameter Passing:**
```c
int function(int a, int b, int c, int d, int e, int f, int g, int h) {
    // a → %rdi, b → %rsi, c → %rdx, d → %rcx, e → %r8, f → %r9
    // g and h go on stack at +16(%rbp) and +24(%rbp)
}
```

**Function Entry/Exit:**
```assembly
# Function prologue
pushq %rbp                     # Save caller's frame pointer
movq %rsp, %rbp               # Set up new frame pointer
subq $32, %rsp                # Allocate space for locals

# Parameter handling (first 6 in registers)
movl %edi, -4(%rbp)           # Store parameter 'a'
movl %esi, -8(%rbp)           # Store parameter 'b'

# Function epilogue  
movq %rbp, %rsp               # Restore stack pointer
popq %rbp                     # Restore caller's frame pointer
ret                           # Return to caller
```

### 7.3.2.4 Scope vs Storage Distinction

**Important Conceptual Point:**
- **Scope**: Where a name is visible (compile-time concept)
- **Storage**: When memory is allocated (runtime concept)

```c
void function() {
    int local_var;              // Function scope, automatic storage
    static int static_var;      // Function scope, static storage
    
    {
        int block_var;          // Block scope, automatic storage
    }
    // block_var out of scope, but 'local_var' still has function scope
}
```

### 7.3.2.5 Automatic Variable Advantages

**1. Memory Efficiency**
```c
void recursive_function(int depth) {
    int local_data[100];        // Each recursion gets own copy
    if (depth > 0) {
        recursive_function(depth - 1);
    }
    // local_data automatically freed when function returns
}
```

**2. Efficient Addressing**
```assembly
# Small offsets use 1-byte displacement encoding
movl -8(%rbp), %eax           # 3 bytes: opcode + ModR/M + disp8

# Large offsets require 4-byte displacement
movl -1000(%rbp), %eax        # 6 bytes: opcode + ModR/M + disp32
```

**3. Thread Safety**
```c
void thread_safe_function() {
    int thread_local = 0;       // Each thread gets own copy
    thread_local++;             // No synchronization needed
}
```

**4. Reentrant Code**
```c
int factorial(int n) {
    int result;                 // Each call gets own variable
    if (n <= 1) return 1;
    result = n * factorial(n-1); // Safe recursion
    return result;
}
```

### 7.3.2.6 Automatic Variable Disadvantages

**1. Setup/Teardown Overhead**
```assembly
# Function entry overhead
pushq %rbp                     # 1 instruction
movq %rsp, %rbp               # 1 instruction  
subq $32, %rsp                # 1 instruction (if locals needed)

# Function exit overhead
movq %rbp, %rsp               # 1 instruction
popq %rbp                     # 1 instruction
ret                           # 1 instruction
```

**2. Lost State**
```c
int get_count() {
    int count = 0;              // Reset to 0 every call
    return ++count;             // Always returns 1!
}
```

**3. Stack Overflow Risk**
```c
void dangerous_function() {
    int huge_array[1000000];    // 4MB on stack - may overflow
    // Stack size typically 8MB on Linux, 1MB on Windows
}
```

## 7.3.3 Dynamic Binding and Dynamic Variables

Dynamic variables have their storage allocated explicitly during program execution. The application controls both allocation timing and lifetime, providing maximum flexibility at the cost of complexity.

### 7.3.3.1 Dynamic Storage Characteristics

**Runtime Address Determination:**
```c
int size = get_user_input();    // Size unknown at compile time
int *array = malloc(size * sizeof(int)); // Address determined at runtime
```

**Pointer-Based Access:**
```assembly
# Dynamic variable access requires indirection
movq ptr(%rip), %rax          # Load pointer value
movl (%rax), %edx             # Load data at that address (2 memory accesses)

# Compare with static variable
movl variable(%rip), %edx     # Direct access (1 memory access)
```

### 7.3.3.2 Memory Management

**Heap Structure:**
```
┌─────────────────────┐
│ Metadata Header     │ ← malloc bookkeeping (8-16 bytes)
├─────────────────────┤
│ User Data          │ ← Pointer returned to user
│                    │
├─────────────────────┤
│ Metadata Header     │ ← Next allocation
├─────────────────────┤
│ Free Block         │ ← Available memory
│                    │
└─────────────────────┘
```

**Allocation Example:**
```c
typedef struct {
    size_t size;               // Block size
    int free;                  // 0 = allocated, 1 = free
    struct block *next;        // Next block in list
} block_header_t;

void *malloc(size_t size) {
    // 1. Search free list for suitable block
    // 2. Split block if too large
    // 3. Mark as allocated
    // 4. Return pointer to user data
}
```

### 7.3.3.3 Dynamic Variable Advantages

**1. Flexible Lifetime Control**
```c
int *create_persistent_data() {
    int *data = malloc(100 * sizeof(int));
    // Initialize data...
    return data;                // Outlives function scope
}

void use_data() {
    int *my_data = create_persistent_data();
    // Use data...
    free(my_data);              // Control when to deallocate
}
```

**2. Size Flexibility**
```c
void process_file(const char *filename) {
    FILE *file = fopen(filename, "r");
    fseek(file, 0, SEEK_END);
    long size = ftell(file);     // File size unknown until runtime
    
    char *buffer = malloc(size + 1);  // Allocate exact amount needed
    fread(buffer, 1, size, file);
    // Process buffer...
    free(buffer);
}
```

**3. Efficient Register Usage**
```assembly
# If pointer already in register, access is efficient
movl (%rax), %edx             # Data access using cached pointer
movl 4(%rax), %ecx            # Next element access
```

### 7.3.3.4 Dynamic Variable Disadvantages

**1. Storage Overhead**
```c
int *single_int = malloc(sizeof(int));  // 4 bytes data + 8-16 bytes metadata
                                        // 200-400% overhead!
```

**2. Performance Costs**
```c
// Memory access comparison
static int static_var;          // 1 memory access
int local_var;                  // 0 memory accesses (may be in register)
int *dynamic_var = malloc(4);   // 2 memory accesses (pointer + data)
```

**3. Allocation/Deallocation Overhead**
```c
clock_t start = clock();

// Stack allocation (very fast)
for (int i = 0; i < 1000000; i++) {
    int stack_array[100];       // ~1 nanosecond
}

// Heap allocation (much slower) 
for (int i = 0; i < 1000000; i++) {
    int *heap_array = malloc(100 * sizeof(int));  // ~100 nanoseconds
    free(heap_array);
}
```

**4. Memory Management Complexity**
```c
// Memory leak example
void problematic_function() {
    int *data = malloc(1000);
    
    if (error_condition) {
        return;                 // LEAK: forgot to free!
    }
    
    process_data(data);
    free(data);                 // Only freed in success case
}

// Correct approach
void correct_function() {
    int *data = malloc(1000);
    
    if (error_condition) {
        free(data);             // Clean up before return
        return;
    }
    
    process_data(data);
    free(data);
}
```

**5. Fragmentation Issues**
```c
// External fragmentation example
int *ptrs[1000];

// Allocate many small blocks
for (int i = 0; i < 1000; i++) {
    ptrs[i] = malloc(64);
}

// Free every other block
for (int i = 0; i < 1000; i += 2) {
    free(ptrs[i]);
}

// Now have 500 free 64-byte blocks, but can't satisfy malloc(1000)
// Even though total free space > 1000 bytes
```

## Storage Type Performance Comparison

### Access Speed (typical cycles on modern x86-64)
| Storage Type | Access Method | Cycles | Example |
|--------------|---------------|---------|---------|
| Register | Direct | 1 | `%eax` |
| Stack (L1 cache) | Base+offset | 3-4 | `-8(%rbp)` |
| Static (L1 cache) | RIP-relative | 3-4 | `var(%rip)` |
| Heap (L1 cache) | Pointer indirect | 6-8 | `*ptr` |
| Heap (main memory) | Pointer indirect | 200+ | `*ptr` (cache miss) |

### Memory Overhead
| Storage Type | Overhead | Notes |
|--------------|----------|-------|
| Static | 0 bytes | No runtime bookkeeping |
| Automatic | 0 bytes | Stack management by hardware |
| Dynamic | 8-16 bytes | malloc metadata per allocation |

### Allocation Speed
| Storage Type | Speed | Mechanism |
|--------------|-------|-----------|
| Automatic | ~1 cycle | Stack pointer adjustment |
| Static | 0 cycles | Pre-allocated |
| Dynamic | ~100-1000 cycles | Heap search and bookkeeping |

## Choosing the Right Storage Type

### Decision Matrix

**Use Static Storage When:**
- ✅ Value needs to persist across function calls
- ✅ Variable accessed frequently throughout program
- ✅ Size known at compile time
- ✅ Single-threaded or properly synchronized access

**Use Automatic Storage When:**
- ✅ Variable only needed within function scope
- ✅ Size known at compile time
- ✅ Maximum performance required
- ✅ Thread safety important

**Use Dynamic Storage When:**
- ✅ Size unknown until runtime
- ✅ Lifetime extends beyond creating scope
- ✅ Large data structures (avoid stack overflow)
- ✅ Flexible memory management needed

### Modern Considerations

**Cache-Friendly Programming:**
```c
// Good: locality of reference
struct Point { int x, y; };
struct Point points[1000];      // Array of structures

// Bad: poor cache utilization  
struct Point *points[1000];     // Array of pointers to scattered objects
for (int i = 0; i < 1000; i++) {
    points[i] = malloc(sizeof(struct Point));
}
```

**RAII in C++ (Resource Acquisition Is Initialization):**
```cpp
class AutoBuffer {
    char *buffer;
public:
    AutoBuffer(size_t size) : buffer(new char[size]) {}
    ~AutoBuffer() { delete[] buffer; }          // Automatic cleanup
};
```

**Smart Pointers:**
```cpp
std::unique_ptr<int[]> data(new int[1000]);    // Automatic deallocation
std::shared_ptr<int> shared_data = std::make_shared<int>(42);
```

Understanding these storage types and their trade-offs is essential for writing efficient, correct, and maintainable code. The choice of storage type affects not just performance, but also correctness, especially in multi-threaded environments.